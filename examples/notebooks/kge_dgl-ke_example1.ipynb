{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRKG - Knowledge Graph Embedding\n",
    ">\n",
    "> biomedgps-hsdn-custom-malacards-ctd vs. biomedgps-hsdn-custom-malacards\n",
    ">\n",
    "> Based on the biomedgps-hsdn-custom-malacards- dataset, we add the following datasets: ctd.\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "WARNING: A conda environment already exists at '/opt/conda/envs/biomedgps'\n",
      "Remove existing environment (y/[n])? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaSystemExit: Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# We assume you are using a conda environment\n",
    "# torchvision==0.14.0 & torch==1.13 only work with CUDA==1.16 or CUDA==1.17 and python==3.10\n",
    "mamba create -n biomedgps python==3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# If you have installed CUDA==1.16 or CUDA==1.17, you can use the following command to install torch==1.13\n",
    "# dglke is compatible with dgl==0.9.0 and dgl==0.9.0 only works with torch==1.13\n",
    "pip3 install torch==1.13 torchvision==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install git+https://github.com/awslabs/dgl-ke.git#subdirectory=python && pip install ogb dgl==0.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get formatted + unformatted DRKG from the [biomedgps-data repo](https://github.com/yjcyxky/biomedgps-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the file\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "rootdir = os.path.join(os.getcwd())\n",
    "datadir = os.path.join(rootdir, 'data')\n",
    "models_dir = os.path.join(rootdir, 'models')\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./formatted_drkg.tsv.zip\n",
      "caution: filename not matched:  -y\n",
      "Archive:  ./unformatted_drkg.tsv.zip\n",
      "caution: filename not matched:  -y\n"
     ]
    }
   ],
   "source": [
    "!cd ./data && unzip ./formatted_drkg.tsv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./unformatted_drkg.tsv.zip\n",
      "replace unformatted_drkg.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!cd ./data && unzip ./unformatted_drkg.tsv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted DRKG data shape:  (5678569, 6)\n",
      "Unformatted DRKG data shape:  (194412, 6)\n",
      "Duplicated DRKG data shape:  (2499, 6)\n",
      "Custom KG data shape:  (602, 6)\n",
      "Malacards data shape:  (201, 6)\n",
      "Formatted HSDN data shape:  (130857, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_668044/1149273680.py:30: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  formatted_ctd = pd.read_csv(os.path.join(datadir, 'formatted_ctd.tsv'), sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted CTD data shape:  (34133278, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "selected_columns = [\"relation_type\", \"source_type\", \"source_id\", \"target_type\", \"target_id\", \"resource\"]\n",
    "\n",
    "formatted_drkg_data = pd.read_csv(os.path.join(datadir, 'formatted_drkg.tsv'), sep='\\t')\n",
    "formatted_drkg_data = formatted_drkg_data[selected_columns]\n",
    "print(\"Formatted DRKG data shape: \", formatted_drkg_data.shape)\n",
    "\n",
    "unformatted_drkg_data = pd.read_csv(os.path.join(datadir, 'unformatted_drkg.tsv'), sep='\\t')\n",
    "unformatted_drkg_data = unformatted_drkg_data[selected_columns]\n",
    "print(\"Unformatted DRKG data shape: \", unformatted_drkg_data.shape)\n",
    "\n",
    "duplicated_drkg_data = pd.read_csv(os.path.join(datadir, 'duplicated_drkg.tsv'), sep='\\t')\n",
    "duplicated_drkg_data = duplicated_drkg_data[selected_columns]\n",
    "print(\"Duplicated DRKG data shape: \", duplicated_drkg_data.shape)\n",
    "\n",
    "custom_kg = pd.read_csv(os.path.join(datadir, 'custom_kg.tsv'), sep='\\t')\n",
    "custom_kg = custom_kg[selected_columns]\n",
    "print(\"Custom KG data shape: \", custom_kg.shape)\n",
    "\n",
    "malacards = pd.read_csv(os.path.join(datadir, 'malacards.tsv'), sep='\\t')\n",
    "malacards = malacards[selected_columns]\n",
    "print(\"Malacards data shape: \", malacards.shape)\n",
    "\n",
    "formatted_hsdn = pd.read_csv(os.path.join(datadir, 'formatted_hsdn.tsv'), sep='\\t')\n",
    "formatted_hsdn = formatted_hsdn[selected_columns]\n",
    "print(\"Formatted HSDN data shape: \", formatted_hsdn.shape)\n",
    "\n",
    "formatted_ctd = pd.read_csv(os.path.join(datadir, 'formatted_ctd.tsv'), sep='\\t')\n",
    "formatted_ctd = formatted_ctd[selected_columns]\n",
    "print(\"Formatted CTD data shape: \", formatted_ctd.shape)\n",
    "\n",
    "relations = pd.concat([formatted_drkg_data, unformatted_drkg_data, duplicated_drkg_data, custom_kg, malacards, formatted_hsdn, formatted_ctd])\n",
    "\n",
    "# Save the merged data\n",
    "relations.to_csv(os.path.join(datadir, 'relations.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40140418"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# Merge the source_type and source_id columns\n",
    "df['merged_source_id'] = relations['source_type'] + '::' + relations['source_id'].astype(str)\n",
    "\n",
    "# Merge the target_type and target_id columns\n",
    "df['merged_target_id'] = relations['target_type'] + '::' + relations['target_id'].astype(str)\n",
    "\n",
    "df['relation_type'] = relations['relation_type']\n",
    "\n",
    "# Reorder the columns\n",
    "df = df[['merged_source_id', 'relation_type', 'merged_target_id']]\n",
    "\n",
    "# Remove the header\n",
    "df.to_csv(os.path.join(datadir, 'relations_hrt.tsv'), sep='\\t', index=False, header=False)\n",
    "\n",
    "triples = df.values.tolist()\n",
    "num_triples = len(triples)\n",
    "num_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36126376 2007020 2007022\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "# Please make sure the output directory exist.\n",
    "seed = np.arange(num_triples)\n",
    "np.random.shuffle(seed)\n",
    "\n",
    "train_cnt = int(num_triples * 0.9)\n",
    "valid_cnt = int(num_triples * 0.05)\n",
    "train_set = seed[:train_cnt]\n",
    "train_set = train_set.tolist()\n",
    "valid_set = seed[train_cnt:train_cnt+valid_cnt].tolist()\n",
    "test_set = seed[train_cnt+valid_cnt:].tolist()\n",
    "\n",
    "train_dir = os.path.join(rootdir, \"data/train\")\n",
    "train_datafile = os.path.join(train_dir, \"train.tsv\")\n",
    "valid_datafile = os.path.join(train_dir, \"valid.tsv\")\n",
    "test_datafile = os.path.join(train_dir, \"test.tsv\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "with open(train_datafile, 'w+') as f:\n",
    "    for idx in train_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "        \n",
    "with open(valid_datafile, 'w+') as f:\n",
    "    for idx in valid_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "\n",
    "with open(test_datafile, 'w+') as f:\n",
    "    for idx in test_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "\n",
    "print(len(train_set), len(valid_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# You must change the DATASET_NAME according to your situation\n",
    "export INDEX=0\n",
    "export MODEL_DIR=./models\n",
    "mkdir -p ${MODEL_DIR}\n",
    "\n",
    "DGLBACKEND=pytorch dglke_train --dataset biomedgps --data_path ./data/train --data_files train.tsv valid.tsv test.tsv --format 'raw_udd_hrt' --model_name TransE_l2 --batch_size 2048 --neg_sample_size 256 --hidden_dim 400 --gamma 12.0 --lr 0.1 --max_step 100000 --log_interval 1000 --batch_size_eval 16 -adv --regularization_coef 1.00E-07 --test --gpu 0 --num_proc 7 --neg_sample_size_eval 10000 --async_update --mix_cpu_gpu --save_path ./models 2>&1 | tee ${MODEL_DIR}/${DATASET_NAME}_${INDEX}_log.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
