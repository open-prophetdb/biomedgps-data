{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training, validation and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to prepare the training, validation and external test datasets. We will use the training dataset to train the model and the test dataset to evaluate the model for all KGE models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Require to Modify According to Your Situation] Prepare all relation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# dataset_name = \"biomedgps-full-v20240127\"\n",
    "dataset_name = \"rapex-v20240627\"\n",
    "skip_rows_not_in_entity_file = True\n",
    "\n",
    "outputdir = os.path.join(root_dir, \"datasets\", dataset_name)\n",
    "graph_data_dir = os.path.join(root_dir, \"graph_data\")\n",
    "\n",
    "formatted_ctd = os.path.join(\n",
    "    graph_data_dir, \"formatted_relations\", \"ctd\", \"formatted_ctd.tsv\"\n",
    ")\n",
    "# formatted_unformatted_drkg = os.path.join(\n",
    "#     graph_data_dir, \"formatted_relations\", \"drkg\", \"unformatted_drkg.tsv\"\n",
    "# )\n",
    "formatted_drkg = os.path.join(\n",
    "    graph_data_dir, \"formatted_relations\", \"drkg\", \"formatted_drkg.tsv\"\n",
    ")\n",
    "formatted_hsdn = os.path.join(\n",
    "    graph_data_dir, \"formatted_relations\", \"hsdn\", \"formatted_hsdn.tsv\"\n",
    ")\n",
    "formatted_primekg = os.path.join(\n",
    "    graph_data_dir, \"formatted_relations\", \"primekg\", \"formatted_primekg.tsv\"\n",
    ")\n",
    "formatted_malacards_mecfs = os.path.join(\n",
    "    graph_data_dir, \"relations\", \"customdb\", \"formatted_malacards_mecfs.tsv\"\n",
    ")\n",
    "formatted_custom = os.path.join(\n",
    "    graph_data_dir, \"relations\", \"customdb\", \"formatted_customdb_v20240329.tsv\"\n",
    ")\n",
    "formatted_treatme_compound = os.path.join(\n",
    "    graph_data_dir, \"relations\", \"customdb\", \"formatted_treatme_survey_compounds.tsv\"\n",
    ")\n",
    "formatted_treatme_symptom = os.path.join(\n",
    "    graph_data_dir, \"relations\", \"customdb\", \"formatted_treatme_survey_symptoms.tsv\"\n",
    ")\n",
    "\n",
    "files = [\n",
    "    formatted_ctd,\n",
    "    # formatted_unformatted_drkg,\n",
    "    formatted_drkg,\n",
    "    formatted_hsdn,\n",
    "    formatted_primekg,\n",
    "    formatted_malacards_mecfs,\n",
    "    formatted_custom,\n",
    "    formatted_treatme_compound,\n",
    "    formatted_treatme_symptom,\n",
    "]\n",
    "\n",
    "print(\"Merging the following files:\")\n",
    "print(\"\\n\".join(files))\n",
    "\n",
    "entity_file = os.path.join(graph_data_dir, \"entities.tsv\")\n",
    "print(\"Number of entities: {}\".format(len(open(entity_file).readlines())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "lib_dir = os.path.join(os.path.dirname(os.getcwd()), \"lib\")\n",
    "\n",
    "print(\"Adding {} to sys.path\".format(lib_dir))\n",
    "sys.path.append(lib_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all relation files into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "args = [\"python3\", os.path.join(lib_dir, \"data.py\"), \"merge-files\"]\n",
    "\n",
    "for f in files:\n",
    "    args.extend([\"--input\", f])\n",
    "\n",
    "kg_file = os.path.join(temp_dir, \"knowledge_graph.tsv\")\n",
    "annotated_kg_file = os.path.join(temp_dir, \"annotated_knowledge_graph.tsv\")\n",
    "args.extend([\"--output\", kg_file])\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(args)))\n",
    "args_str = \" \".join(args)\n",
    "!{args_str}\n",
    "\n",
    "if os.path.exists(kg_file):\n",
    "    df = pd.read_csv(kg_file, sep=\"\\t\")\n",
    "    source_ids = df[[\"source_id\", \"source_type\"]].drop_duplicates()\n",
    "    target_ids = df[[\"target_id\", \"target_type\"]].drop_duplicates()\n",
    "    ids = pd.concat([source_ids, target_ids]).drop_duplicates()\n",
    "    print(\"Number of unique entity ids: {}\".format(len(ids)))\n",
    "    print(\"Number of relations: {}\".format(len(df.drop_duplicates())))\n",
    "\n",
    "# Annotate the knowledge graph with the entities\n",
    "args = [\n",
    "    \"python3\",\n",
    "    os.path.join(os.path.dirname(lib_dir), \"graph_data\", \"scripts\", \"annotate_relations.py\"),\n",
    "    \"--entity-file\",\n",
    "    entity_file,\n",
    "    \"--relation-file\",\n",
    "    kg_file,\n",
    "    \"--output-dir\",\n",
    "    os.path.dirname(kg_file),\n",
    "    \"--strict-mode\" if skip_rows_not_in_entity_file else \"\",\n",
    "]\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(args)))\n",
    "args_str = \" \".join(args)\n",
    "!{args_str}\n",
    "print(\"File written to: {}\".format(annotated_kg_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the merged relation file into training, validation and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_file = os.path.join(temp_dir, \"train_validation.tsv\")\n",
    "train_file = os.path.join(temp_dir, \"train.tsv\")\n",
    "test_file = os.path.join(temp_dir, \"test.tsv\")\n",
    "valid_file = os.path.join(temp_dir, \"valid.tsv\")\n",
    "\n",
    "split_cmd = [\n",
    "    \"python3\",\n",
    "    os.path.join(lib_dir, \"data.py\"),\n",
    "    \"split\",\n",
    "    \"--input\",\n",
    "    kg_file,\n",
    "    \"--output-1\",\n",
    "    train_validation_file,\n",
    "    \"--output-2\",\n",
    "    test_file,\n",
    "    \"--ratio\",\n",
    "    \"0.95\",\n",
    "]\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(split_cmd)))\n",
    "split_cmd_str = \" \".join(split_cmd)\n",
    "!{split_cmd_str}\n",
    "print(f\"Split files created: {train_validation_file} and {test_file}.\")\n",
    "\n",
    "split_cmd = [\n",
    "    \"python3\",\n",
    "    os.path.join(lib_dir, \"data.py\"),\n",
    "    \"split\",\n",
    "    \"--input\",\n",
    "    train_validation_file,\n",
    "    \"--output-1\",\n",
    "    train_file,\n",
    "    \"--output-2\",\n",
    "    valid_file,\n",
    "    \"--ratio\",\n",
    "    \"0.95\",\n",
    "]\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(split_cmd)))\n",
    "split_cmd_str = \" \".join(split_cmd)\n",
    "!{split_cmd_str}\n",
    "print(\"Split files created: {} and {}.\".format(train_file, valid_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether number of ids in train, validation, and test are the same.\n",
    "If you see the following message, you need to run the section \"Keep the same number of ids in train, validation, and test\" in the notebook.\n",
    "\n",
    "```\n",
    "ValueError: You need to keep the entity ids and relation types in the test and validation files the same as the ones in the train file.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_checked_file = os.path.join(temp_dir, \"id_checked.tsv\")\n",
    "check_ids_cmd = [\n",
    "    \"python3\",\n",
    "    os.path.join(lib_dir, \"data.py\"),\n",
    "    \"check-ids\",\n",
    "    \"--input\",\n",
    "    train_file,\n",
    "    \"--input\",\n",
    "    valid_file,\n",
    "    \"--input\",\n",
    "    test_file,\n",
    "    \"--output\",\n",
    "    id_checked_file,\n",
    "]\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(check_ids_cmd)))\n",
    "check_ids_cmd_str = \" \".join(check_ids_cmd)\n",
    "# Catch the error\n",
    "check_ids_cmd_str += \" || true\"\n",
    "!{check_ids_cmd_str}\n",
    "print(\"Checked files created: {}.\".format(id_checked_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep the entity id and relation type same among validation, test and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_valid_dir = os.path.join(temp_dir, \"keep_valid\")\n",
    "os.makedirs(keep_valid_dir, exist_ok=True)\n",
    "\n",
    "keep_valid_cmd = [\n",
    "    \"python3\",\n",
    "    os.path.join(lib_dir, \"data.py\"),\n",
    "    \"keep-valid\",\n",
    "    \"--train-file\",\n",
    "    train_file,\n",
    "    \"--valid-file\",\n",
    "    valid_file,\n",
    "    \"--test-file\",\n",
    "    test_file,\n",
    "    \"--output-dir\",\n",
    "    keep_valid_dir,\n",
    "]\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(keep_valid_cmd)))\n",
    "keep_valid_cmd_str = \" \".join(keep_valid_cmd)\n",
    "!{keep_valid_cmd_str}\n",
    "print(\"Files created: {}.\".format(os.listdir(keep_valid_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Again] Check whether number of ids in train, validation, and test are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_checked_file = os.path.join(keep_valid_dir, \"id_checked.tsv\")\n",
    "train_valid_file = os.path.join(keep_valid_dir, \"train_valid.tsv\")\n",
    "valid_valid_file = os.path.join(keep_valid_dir, \"valid_valid.tsv\")\n",
    "test_valid_file = os.path.join(keep_valid_dir, \"test_valid.tsv\")\n",
    "\n",
    "check_ids_cmd = [\n",
    "    \"python3\",\n",
    "    os.path.join(lib_dir, \"data.py\"),\n",
    "    \"check-ids\",\n",
    "    \"--input\",\n",
    "    train_valid_file,\n",
    "    \"--input\",\n",
    "    valid_valid_file,\n",
    "    \"--input\",\n",
    "    test_valid_file,\n",
    "    \"--output\",\n",
    "    id_checked_file,\n",
    "]\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(check_ids_cmd)))\n",
    "check_ids_cmd_str = \" \".join(check_ids_cmd)\n",
    "!{check_ids_cmd_str}\n",
    "print(\"Checked files created: {}.\".format(id_checked_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrt_dir = os.path.join(temp_dir, \"hrt\")\n",
    "os.makedirs(hrt_dir, exist_ok=True)\n",
    "\n",
    "files = [\n",
    "    (os.path.join(keep_valid_dir, \"train_valid.tsv\"), os.path.join(hrt_dir, \"train.tsv\")),\n",
    "    (os.path.join(keep_valid_dir, \"valid_valid.tsv\"), os.path.join(hrt_dir, \"valid.tsv\")),\n",
    "    (os.path.join(keep_valid_dir, \"test_valid.tsv\"), os.path.join(hrt_dir, \"test.tsv\")),\n",
    "]\n",
    "\n",
    "for input_file, output_file in files:\n",
    "    hrt_cmd = [\n",
    "        \"python3\",\n",
    "        os.path.join(lib_dir, \"data.py\"),\n",
    "        \"hrt\",\n",
    "        \"--input\",\n",
    "        input_file,\n",
    "        \"--output\",\n",
    "        output_file,\n",
    "    ]\n",
    "\n",
    "    print(\"Running: {}\".format(\" \".join(hrt_cmd)))\n",
    "    hrt_cmd_str = \" \".join(hrt_cmd)\n",
    "    !{hrt_cmd_str}\n",
    "    print(\"HRT files created: {}.\".format(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy all files to the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(outputdir, exist_ok=True)\n",
    "\n",
    "files = [\n",
    "    (os.path.join(hrt_dir, \"train.tsv\"), os.path.join(outputdir, \"train.tsv\")),\n",
    "    (os.path.join(hrt_dir, \"valid.tsv\"), os.path.join(outputdir, \"valid.tsv\")),\n",
    "    (os.path.join(hrt_dir, \"test.tsv\"), os.path.join(outputdir, \"test.tsv\")),\n",
    "    (\n",
    "        os.path.join(keep_valid_dir, \"id_checked.tsv\"),\n",
    "        os.path.join(outputdir, \"id_checked.tsv\"),\n",
    "    ),\n",
    "    (entity_file, os.path.join(outputdir, \"annotated_entities.tsv\")),\n",
    "    (kg_file, os.path.join(outputdir, \"knowledge_graph.tsv\")),\n",
    "    (annotated_kg_file, os.path.join(outputdir, \"annotated_knowledge_graph.tsv\")),\n",
    "]\n",
    "\n",
    "for f, output_file in files:\n",
    "    subprocess.check_output([\"cp\", f, output_file])\n",
    "\n",
    "print(\"Please found all files in {}\".format(outputdir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedgps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
