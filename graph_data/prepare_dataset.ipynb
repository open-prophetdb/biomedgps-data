{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a full knowledge graph dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to prepare the training, validation and external test datasets. We will use the training dataset to train the model and the test dataset to evaluate the model for all KGE models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Require to Modify According to Your Situation] Prepare all relation files\n",
    "\n",
    "We design a strategy to allow users to integrate their expected relation files for different purposes. Such as you might want to include the `malacards_mecfs` dataset when you want to train a model for ME/CFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# ---------- Parameters [Must be modified based on your situation] ----------\n",
    "# dataset_name = \"biomedgps-full-v20240127\"\n",
    "dataset_name = \"biomedgps\"\n",
    "dataset_version = \"v20241115\"\n",
    "skip_rows_not_in_entity_file = True\n",
    "# The directory names must be consistent with the subdirectories in the formatted_relations folder.\n",
    "blacklist_databases = [\"ctd\"]\n",
    "\n",
    "# It's an optional parameter, if you don't want to split the dataset, you can ignore it.\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Which column will be kept in the final formatted file\n",
    "relation_type_column = \"formatted_relation_type\"\n",
    "\n",
    "# Which file will be used to format the relation types\n",
    "relation_type_file = \"relation_types.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the following files:\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_disease/formatted_customdb.tsv\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_phenotype/formatted_customdb.tsv\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/cbcg/formatted_customdb.tsv\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/customdb/formatted_customdb.tsv\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/drkg/formatted_drkg.tsv\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/hsdn/formatted_hsdn.tsv\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/primekg/formatted_primekg.tsv\n",
      "/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/ttd/formatted_customdb.tsv\n",
      "Number of entities: 926803\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load data ----------\n",
    "graph_data_dir = os.path.join(root_dir, \"graph_data\")\n",
    "formatted_relation_dir = os.path.join(graph_data_dir, \"formatted_relations\")\n",
    "\n",
    "files = []\n",
    "for dir in os.listdir(formatted_relation_dir):\n",
    "    for file in os.listdir(os.path.join(formatted_relation_dir, dir)):\n",
    "        if file.endswith(\".tsv\") and file.startswith(\"formatted_\") and dir not in blacklist_databases:\n",
    "            files.append(os.path.join(formatted_relation_dir, dir, file))\n",
    "files = sorted(files)\n",
    "\n",
    "print(\"Merging the following files:\")\n",
    "print(\"\\n\".join(files))\n",
    "\n",
    "entity_file = os.path.join(graph_data_dir, \"entities.tsv\")\n",
    "print(\"Number of entities: {}\".format(len(open(entity_file).readlines())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/lib to sys.path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "lib_dir = os.path.join(os.path.dirname(os.getcwd()), \"lib\")\n",
    "\n",
    "print(\"Adding {} to sys.path\".format(lib_dir))\n",
    "sys.path.append(lib_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata for recording the steps\n",
    "\n",
    "To save the essential information of all relation files for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metadata import DatasetMetadata, check_repo_clean\n",
    "\n",
    "# For getting the correct commit id, we need to check if the repo is clean. If not, you should commit your changes first.\n",
    "check_repo_clean(file_suffix = \".py\", raise_error=False)\n",
    "repo_commit_id = os.popen(\"git rev-parse HEAD\").read().strip()\n",
    "repo_path = os.popen(\"git config --get remote.origin.url\").read().strip()\n",
    "outputdir = os.path.join(root_dir, \"datasets\", f\"{dataset_name}-{dataset_version}-{repo_commit_id[:6]}\")\n",
    "os.makedirs(outputdir, exist_ok=True)\n",
    "\n",
    "dataset_metadata = DatasetMetadata(\n",
    "    repo_commit_id=repo_commit_id,\n",
    "    repo_path=repo_path,\n",
    "    dataset_name=dataset_name,\n",
    "    dataset_version=dataset_version,\n",
    "    data_files=files,\n",
    "    metadata=None,\n",
    ")\n",
    "\n",
    "dataset_metadata.to_json(os.path.join(outputdir, \"metadata.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all relation files into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python3 /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/lib/data.py merge-files --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_disease/formatted_customdb.tsv --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_phenotype/formatted_customdb.tsv --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/cbcg/formatted_customdb.tsv --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/customdb/formatted_customdb.tsv --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/drkg/formatted_drkg.tsv --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/hsdn/formatted_hsdn.tsv --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/primekg/formatted_primekg.tsv --input /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/ttd/formatted_customdb.tsv --output /var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/tmpqt_3oatn/knowledge_graph.tsv\n",
      "Merging the following files:  ('/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_disease/formatted_customdb.tsv', '/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_phenotype/formatted_customdb.tsv', '/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/cbcg/formatted_customdb.tsv', '/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/customdb/formatted_customdb.tsv', '/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/drkg/formatted_drkg.tsv', '/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/hsdn/formatted_hsdn.tsv', '/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/primekg/formatted_primekg.tsv', '/Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/ttd/formatted_customdb.tsv')\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_disease/formatted_customdb.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 85590\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/biosnap_phenotype/formatted_customdb.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 85386\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/cbcg/formatted_customdb.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 432\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/customdb/formatted_customdb.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 990\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/drkg/formatted_drkg.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 5492952\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/hsdn/formatted_hsdn.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 127339\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/primekg/formatted_primekg.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 8035388\n",
      "The following columns are in the /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/formatted_relations/ttd/formatted_customdb.tsv: ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type'], Number of rows: 14027\n",
      "The following columns will be used:  ['raw_source_id', 'raw_target_id', 'raw_source_type', 'raw_target_type', 'relation_type', 'resource', 'pmids', 'key_sentence', 'source_id', 'source_type', 'target_id', 'target_type', 'formatted_relation_type']\n",
      "Number of rows in the merged dataframe:  13842104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/ipykernel_59369/3759005214.py:21: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(kg_file, sep=\"\\t\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entity ids: 146969\n",
      "Number of deduplicated relations: 13842104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/ipykernel_59369/3759005214.py:30: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  entities = pd.read_csv(entity_file, sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "args = [\"python3\", os.path.join(lib_dir, \"data.py\"), \"merge-files\"]\n",
    "\n",
    "for f in files:\n",
    "    args.extend([\"--input\", f])\n",
    "\n",
    "kg_file = os.path.join(temp_dir, \"knowledge_graph.tsv\")\n",
    "args.extend([\"--output\", kg_file])\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(args)))\n",
    "args_str = \" \".join(args)\n",
    "!{args_str}\n",
    "\n",
    "if os.path.exists(kg_file):\n",
    "    df = pd.read_csv(kg_file, sep=\"\\t\")\n",
    "    source_ids = df[[\"source_id\", \"source_type\"]].drop_duplicates()\n",
    "    source_ids.columns = [\"id\", \"label\"]\n",
    "    target_ids = df[[\"target_id\", \"target_type\"]].drop_duplicates()\n",
    "    target_ids.columns = [\"id\", \"label\"]\n",
    "    ids = pd.concat([source_ids, target_ids]).drop_duplicates()\n",
    "    print(\"Number of unique entity ids: {}\".format(len(ids)))\n",
    "    print(\"Number of deduplicated relations: {}\".format(len(df.drop_duplicates())))\n",
    "\n",
    "    entities = pd.read_csv(entity_file, sep=\"\\t\")\n",
    "\n",
    "    dataset_metadata.add_step(\n",
    "        note=\"Merge all relation files into one file\",\n",
    "        entity_file_before=None,\n",
    "        entity_file_after=entity_file,\n",
    "        relation_file_before=None,\n",
    "        relation_file_after=kg_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Filter out the relations that are not matched with our requirements\n",
    "\n",
    "We can follow the results generated by the graph_analysis.ipynb to decide which relations should be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The kg_file variable might have been updated by the following cells, so we put the definition here for avoiding to load the wrong file\n",
    "kg_file = os.path.join(temp_dir, \"knowledge_graph.tsv\")\n",
    "df = pd.read_csv(kg_file, sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of relations: {}\".format(len(df)))\n",
    "ignore_relation_types = [\n",
    "    # Virus gene relations are not useful for our use case.\n",
    "    \"bioarx::Coronavirus_ass_host_gene::Disease:Gene\",\n",
    "    \"bioarx::Covid2_acc_host_gene::Disease:Gene\",\n",
    "    \"bioarx::DrugHumGen::Compound:Gene\",\n",
    "    \"bioarx::DrugVirGen::Compound:Gene\",\n",
    "    \"bioarx::HumGenHumGen::Gene:Gene\",\n",
    "    \"bioarx::VirGenHumGen::Gene:Gene\",\n",
    "    # We don't like associated_with relation type.\n",
    "    \"PrimeKG::associated_with::Disease:Gene\",\n",
    "    \"PrimeKG::associated_with::Gene:Disease\",\n",
    "    \"PrimeKG::associated_with::Gene:Symptom\",\n",
    "    \"PrimeKG::associated_with::Symptom:Gene\",\n",
    "    # We don't like ontology tree\n",
    "    \"PrimeKG::parent-child::Anatomy:Anatomy\",\n",
    "    \"PrimeKG::parent-child::BiologicalProcess:BiologicalProcess\",\n",
    "    \"PrimeKG::parent-child::CellularComponent:CellularComponent\",\n",
    "    \"PrimeKG::parent-child::Disease:Disease\",\n",
    "    \"PrimeKG::parent-child::MolecularFunction:MolecularFunction\",\n",
    "    \"PrimeKG::parent-child::Pathway:Pathway\",\n",
    "    \"PrimeKG::parent-child::Symptom:Symptom\",\n",
    "]\n",
    "\n",
    "df = df[~df[\"relation_type\"].isin(ignore_relation_types)]\n",
    "print(\"Number of relations after removed ignore relation_types: {}\".format(len(df)))\n",
    "\n",
    "relation_type_map = pd.read_csv(\n",
    "    os.path.join(graph_data_dir, \"relation_types.tsv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "relation_types = relation_type_map[\"relation_type\"].tolist()\n",
    "df = df[df[\"relation_type\"].isin(relation_types)]\n",
    "print(\"Number of relations after removed unknown relation_types: {}\".format(len(df)))\n",
    "kg_file_ignore_relation_types_filtered = os.path.join(\n",
    "    temp_dir, \"knowledge_graph_ignore_relation_types_filtered.tsv\"\n",
    ")\n",
    "df = df.merge(relation_type_map[[\"relation_type\", \"formatted_relation_type\"]], on=\"relation_type\", how=\"left\")\n",
    "\n",
    "ignore_formatted_relation_types = [\n",
    "    # There are too much relations in this relation type, but they might not useful.\n",
    "    \"BioMedGPS::Interaction::Compound:Compound\",\n",
    "    # We don't like associated_with relation type.\n",
    "    \"BioMedGPS::AssociatedWith::Gene:Gene\",\n",
    "]\n",
    "df = df[~df[\"formatted_relation_type\"].isin(ignore_formatted_relation_types)]\n",
    "print(\"Number of relations after removed ignore formatted_relation_types: {}\".format(len(df)))\n",
    "\n",
    "df.to_csv(kg_file_ignore_relation_types_filtered, sep=\"\\t\", index=False)\n",
    "kg_file = kg_file_ignore_relation_types_filtered\n",
    "kg_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Map all mouse genes to human genes as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of Mouse / Rat / Human Genes\n",
    "entities = pd.read_csv(entity_file, sep=\"\\t\")\n",
    "genes = entities[entities[\"label\"] == \"Gene\"]\n",
    "mouse_genes = genes[genes[\"taxid\"] == 10090]\n",
    "rat_genes = genes[genes[\"taxid\"] == 10116]\n",
    "human_genes = genes[genes[\"taxid\"] == 9606]\n",
    "\n",
    "print(\"Number of Entities: \", len(mouse_genes), len(rat_genes), len(human_genes))\n",
    "knowledge_graph = pd.read_csv(kg_file, sep=\"\\t\")\n",
    "mouse_relations = knowledge_graph[\n",
    "    knowledge_graph[\"source_id\"].isin(mouse_genes[\"id\"])\n",
    "    | knowledge_graph[\"target_id\"].isin(mouse_genes[\"id\"])\n",
    "]\n",
    "\n",
    "human_relations = knowledge_graph[\n",
    "    knowledge_graph[\"source_id\"].isin(human_genes[\"id\"])\n",
    "    | knowledge_graph[\"target_id\"].isin(human_genes[\"id\"])\n",
    "]\n",
    "\n",
    "print(f\"Number of mouse gene relations: {len(mouse_relations)}, Number of human gene relations: {len(human_relations)}\")\n",
    "\n",
    "human_mouse_gene_mappings = pd.read_csv(\n",
    "    os.path.join(graph_data_dir, \"mapping\", \"human_mouse_gene_mappings.tsv\"), sep=\"\\t\"\n",
    ")\n",
    "# NOTE: There might be multiple mappings for a single mouse gene, we will use the first mapping for now. such as PTCD1[ENTREZ:26024] and ATP5MF-PTCD1[ENTREZ:100526740] have the same mouse gene mapping. Ptcd1[ENTREZ: 71799]. \n",
    "# human_mouse_gene_map[\"ENTREZ:71799\"]\n",
    "human_mouse_gene_map = dict(\n",
    "    zip(\n",
    "        human_mouse_gene_mappings[\"entrez_id_mouse\"],\n",
    "        human_mouse_gene_mappings[\"entrez_id_human\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't like mouse genes, let's convert them to human genes. If a mouse gene doesn't have a human gene mapping, we will keep the mouse gene. So the users can see that the gene is a mouse gene.\n",
    "# Convert the mouse_genes[\"id\"] Series to a set for faster lookup\n",
    "mouse_gene_ids = set(mouse_genes[\"id\"].values)\n",
    "\n",
    "# Vectorized operation for source_id\n",
    "knowledge_graph[\"source_id\"] = knowledge_graph[\"source_id\"].map(\n",
    "    lambda x: human_mouse_gene_map.get(x, x) if x in mouse_gene_ids else x\n",
    ")\n",
    "\n",
    "# Vectorized operation for target_id\n",
    "knowledge_graph[\"target_id\"] = knowledge_graph[\"target_id\"].map(\n",
    "    lambda x: human_mouse_gene_map.get(x, x) if x in mouse_gene_ids else x\n",
    ")\n",
    "\n",
    "# Check whether the conversion is successful\n",
    "converted_mouse_relations = knowledge_graph[\n",
    "    knowledge_graph[\"source_id\"].isin(mouse_genes[\"id\"])\n",
    "    | knowledge_graph[\"target_id\"].isin(mouse_genes[\"id\"])\n",
    "]\n",
    "\n",
    "converted_human_relations = knowledge_graph[\n",
    "    knowledge_graph[\"source_id\"].isin(human_genes[\"id\"])\n",
    "    | knowledge_graph[\"target_id\"].isin(human_genes[\"id\"])\n",
    "]\n",
    "\n",
    "# We cannot use the pattern below because some gene names don't follow the pattern. for example, \"Bdnf\" is used as a human gene in GNBR database.\n",
    "# pattern = r\"^[A-Z][a-z]+$\"\n",
    "# not_matched_genes = knowledge_graph[\n",
    "#     ((knowledge_graph[\"source_type\"] == \"Gene\") & knowledge_graph[\"source_name\"].str.match(pattern, na=False)) |\n",
    "#     ((knowledge_graph[\"target_type\"] == \"Gene\") & knowledge_graph[\"target_name\"].str.match(pattern, na=False))\n",
    "# ]\n",
    "# not_matched_genes[\n",
    "#     (not_matched_genes[\"source_id\"] == \"ENTREZ:627\")\n",
    "#     | (not_matched_genes[\"target_id\"] == \"ENTREZ:627\")\n",
    "# ]\n",
    "\n",
    "converted_not_matched_genes = knowledge_graph[\n",
    "    knowledge_graph[\"source_id\"].isin(mouse_genes[\"id\"])\n",
    "    | knowledge_graph[\"target_id\"].isin(mouse_genes[\"id\"])\n",
    "]\n",
    "\n",
    "# Expected: 0, xxx\n",
    "print(\n",
    "    \"Mouse: \",\n",
    "    len(mouse_relations),\n",
    "    \" Before /\",\n",
    "    len(converted_mouse_relations),\n",
    "    \" After /\",\n",
    "    len(converted_not_matched_genes),\n",
    "    \" Not matched\",\n",
    ")\n",
    "print(\n",
    "    \"Human: \",\n",
    "    len(human_relations),\n",
    "    \" Before /\",\n",
    "    len(converted_human_relations),\n",
    "    \" After\",\n",
    ")\n",
    "\n",
    "# Write the knowledge graph to a file\n",
    "kg_file_mouse_converted = os.path.join(temp_dir, \"knowledge_graph_mouse_converted.tsv\")\n",
    "knowledge_graph.to_csv(kg_file_mouse_converted, sep=\"\\t\", index=False)\n",
    "\n",
    "dataset_metadata.add_step(\n",
    "    note=\"Map all mouse genes to human genes as much as possible\",\n",
    "    entity_file_before=entity_file,\n",
    "    entity_file_after=entity_file,\n",
    "    relation_file_before=kg_file,\n",
    "    relation_file_after=kg_file_mouse_converted,\n",
    ")\n",
    "\n",
    "kg_file = kg_file_mouse_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Format all relation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if relation_type_file and os.path.exists(relation_type_file):\n",
    "    relation_types = pd.read_csv(relation_type_file, sep=\"\\t\")\n",
    "\n",
    "    print(\"Number of relation types: {}\".format(len(relation_types)))\n",
    "\n",
    "    # Read the kg file\n",
    "    knowledge_graph = pd.read_csv(kg_file, sep=\"\\t\")\n",
    "\n",
    "    # Format the relation types\n",
    "    ## Remove the formatted_relation_type column if it exists\n",
    "    if \"formatted_relation_type\" in knowledge_graph.columns:\n",
    "        knowledge_graph = knowledge_graph.drop(columns=[\"formatted_relation_type\"])\n",
    "    knowledge_graph = knowledge_graph.merge(relation_types[[\"relation_type\", \"formatted_relation_type\"]], on=\"relation_type\", how=\"left\")\n",
    "\n",
    "    invalid_knowledge_graph = knowledge_graph[knowledge_graph[\"formatted_relation_type\"].isna()]\n",
    "    print(\"Number of invalid knowledge graph: {}\".format(len(invalid_knowledge_graph)))\n",
    "\n",
    "    invalid_knowledge_graph_file = os.path.join(temp_dir, \"invalid_knowledge_graph.tsv\")\n",
    "    invalid_knowledge_graph.to_csv(invalid_knowledge_graph_file, sep=\"\\t\", index=False)\n",
    "    print(\"Please check the invalid knowledge graph file: {}\".format(invalid_knowledge_graph_file))\n",
    "\n",
    "    kg_file_relation_types_formatted = os.path.join(temp_dir, \"knowledge_graph_relation_types_formatted.tsv\")\n",
    "    knowledge_graph.to_csv(kg_file_relation_types_formatted, sep=\"\\t\", index=False)\n",
    "\n",
    "    dataset_metadata.add_step(\n",
    "        note=\"Format the relation types\",\n",
    "        entity_file_before=entity_file,\n",
    "        entity_file_after=entity_file,\n",
    "        relation_file_before=kg_file,\n",
    "        relation_file_after=kg_file_relation_types_formatted,\n",
    "    )\n",
    "    \n",
    "    kg_file = kg_file_relation_types_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate the knowledge graph with the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python3 /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/scripts/annotate_relations.py --entity-file /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/entities.tsv --relation-file /var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/tmpqt_3oatn/knowledge_graph.tsv --output-dir /var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/tmpqt_3oatn --strict-mode\n",
      "Found 13842104 relations in the input file\n",
      "You're in strict mode, so 0 relations were skipped.\n",
      "File written to: /var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/tmpqt_3oatn/annotated_knowledge_graph.tsv\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"python3\",\n",
    "    os.path.join(os.path.dirname(lib_dir), \"graph_data\", \"scripts\", \"annotate_relations.py\"),\n",
    "    \"--entity-file\",\n",
    "    entity_file,\n",
    "    \"--relation-file\",\n",
    "    kg_file,\n",
    "    \"--output-dir\",\n",
    "    os.path.dirname(kg_file),\n",
    "    \"--strict-mode\" if skip_rows_not_in_entity_file else \"\",\n",
    "]\n",
    "\n",
    "print(\"Running: {}\".format(\" \".join(args)))\n",
    "args_str = \" \".join(args)\n",
    "!{args_str}\n",
    "annotated_kg_file = os.path.join(temp_dir, \"annotated_knowledge_graph.tsv\")\n",
    "print(\"File written to: {}\".format(annotated_kg_file))\n",
    "\n",
    "dataset_metadata.add_step(\n",
    "    note=\"Annotate the knowledge graph with the entities\",\n",
    "    entity_file_before=entity_file,\n",
    "    entity_file_after=entity_file,\n",
    "    relation_file_before=kg_file,\n",
    "    relation_file_after=annotated_kg_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract valid entities from the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "knowledge_graph = pd.read_csv(kg_file, sep=\"\\t\", low_memory=False)\n",
    "entities = pd.read_csv(entity_file, sep=\"\\t\", low_memory=False)\n",
    "\n",
    "source_entities = knowledge_graph[[\"source_id\", \"source_type\"]].drop_duplicates()\n",
    "source_entities.columns = [\"id\", \"label\"]\n",
    "target_entities = knowledge_graph[[\"target_id\", \"target_type\"]].drop_duplicates()\n",
    "target_entities.columns = [\"id\", \"label\"]\n",
    "source_target_entities = pd.concat([source_entities, target_entities]).drop_duplicates()\n",
    "\n",
    "valid_entities = pd.merge(source_target_entities, entities, on=[\"id\", \"label\"], how=\"left\", indicator=True)\n",
    "knowledge_graph_entities_file = os.path.join(temp_dir, \"knowledge_graph_entities.tsv\")\n",
    "valid_entities.to_csv(knowledge_graph_entities_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy all files to the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/graph_data/entities.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_entities.tsv\n",
      "Zipping /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_entities.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_knowledge_graph.tsv.zip\n",
      "Removing /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_entities.tsv\n",
      "Copying /var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/tmpqt_3oatn/knowledge_graph.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/knowledge_graph.tsv\n",
      "Zipping /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/knowledge_graph.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_entities.tsv.zip\n",
      "Removing /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/knowledge_graph.tsv\n",
      "Copying /var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/tmpqt_3oatn/annotated_knowledge_graph.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_knowledge_graph.tsv\n",
      "Zipping /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_knowledge_graph.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/knowledge_graph.tsv.zip\n",
      "Removing /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_knowledge_graph.tsv\n",
      "Copying /var/folders/4s/d4nr1sg91ps1k3qz00h28w_r0000gp/T/tmpqt_3oatn/knowledge_graph_entities.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/knowledge_graph_entities.tsv\n",
      "Zipping /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/knowledge_graph_entities.tsv to /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/annotated_knowledge_graph.tsv.zip\n",
      "Removing /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92/knowledge_graph_entities.tsv\n",
      "Please found all files in /Users/jy006/Documents/Code/BioMedGPS/biomedgps-data/datasets/biomedgps-v20241115-134f92\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(outputdir, exist_ok=True)\n",
    "\n",
    "files = [\n",
    "    (entity_file, os.path.join(outputdir, \"annotated_entities.tsv\")),\n",
    "    (kg_file, os.path.join(outputdir, \"knowledge_graph.tsv\")),\n",
    "    (annotated_kg_file, os.path.join(outputdir, \"annotated_knowledge_graph.tsv\")),\n",
    "    (knowledge_graph_entities_file, os.path.join(outputdir, \"knowledge_graph_entities.tsv\")),\n",
    "]\n",
    "\n",
    "for f, output_file in files:\n",
    "    print(\"Copying {} to {}\".format(f, output_file))\n",
    "    subprocess.check_output([\"cp\", f, output_file])\n",
    "    print(\"Zipping {} to {}\".format(output_file, output_zip_file))\n",
    "    output_zip_file = output_file + \".zip\"\n",
    "    subprocess.check_output([\"zip\", \"-j\", output_zip_file, output_file])\n",
    "    print(\"Removing {}\".format(output_file))\n",
    "    subprocess.check_output([\"rm\", output_file])\n",
    "\n",
    "print(\"Please found all files in {}\".format(outputdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataset to Dropbox and Dataverse\n",
    "\n",
    "You can upload the dataset to Dropbox first, then select the files from Dropbox to upload to Dataverse.\n",
    "\n",
    "https://dataverse.harvard.edu/dataverse/biomedgps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedgps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
